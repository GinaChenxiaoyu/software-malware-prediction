{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "#import xgboost as xgb\n",
    "from scipy.sparse import vstack, csr_matrix, save_npz, load_npz\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from sklearn.metrics import roc_auc_score\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建一个字典，key为特征名，value为变量类型。\n",
    "dtypes = {\n",
    "        'MachineIdentifier':                                    'category',\n",
    "        'ProductName':                                          'category',\n",
    "        'EngineVersion':                                        'category',\n",
    "        'AppVersion':                                           'category',\n",
    "        'AvSigVersion':                                         'category',\n",
    "        'IsBeta':                                               'int8',\n",
    "        'RtpStateBitfield':                                     'float16',\n",
    "        'IsSxsPassiveMode':                                     'int8',\n",
    "        'DefaultBrowsersIdentifier':                            'float16',\n",
    "        'AVProductStatesIdentifier':                            'float32',\n",
    "        'AVProductsInstalled':                                  'float16',\n",
    "        'AVProductsEnabled':                                    'float16',\n",
    "        'HasTpm':                                               'int8',\n",
    "        'CountryIdentifier':                                    'int16',\n",
    "        'CityIdentifier':                                       'float32',\n",
    "        'OrganizationIdentifier':                               'float16',\n",
    "        'GeoNameIdentifier':                                    'float16',\n",
    "        'LocaleEnglishNameIdentifier':                          'int8',\n",
    "        'Platform':                                             'category',\n",
    "        'Processor':                                            'category',\n",
    "        'OsVer':                                                'category',\n",
    "        'OsBuild':                                              'int16',\n",
    "        'OsSuite':                                              'int16',\n",
    "        'OsPlatformSubRelease':                                 'category',\n",
    "        'OsBuildLab':                                           'category',\n",
    "        'SkuEdition':                                           'category',\n",
    "        'IsProtected':                                          'float16',\n",
    "        'AutoSampleOptIn':                                      'int8',\n",
    "        'PuaMode':                                              'category',\n",
    "        'SMode':                                                'float16',\n",
    "        'IeVerIdentifier':                                      'float16',\n",
    "        'SmartScreen':                                          'category',\n",
    "        'Firewall':                                             'float16',\n",
    "        'UacLuaenable':                                         'float32',\n",
    "        'Census_MDC2FormFactor':                                'category',\n",
    "        'Census_DeviceFamily':                                  'category',\n",
    "        'Census_OEMNameIdentifier':                             'float16',\n",
    "        'Census_OEMModelIdentifier':                            'float32',\n",
    "        'Census_ProcessorCoreCount':                            'float16',\n",
    "        'Census_ProcessorManufacturerIdentifier':               'float16',\n",
    "        'Census_ProcessorModelIdentifier':                      'float16',\n",
    "        'Census_ProcessorClass':                                'category',\n",
    "        'Census_PrimaryDiskTotalCapacity':                      'float32',\n",
    "        'Census_PrimaryDiskTypeName':                           'category',\n",
    "        'Census_SystemVolumeTotalCapacity':                     'float32',\n",
    "        'Census_HasOpticalDiskDrive':                           'int8',\n",
    "        'Census_TotalPhysicalRAM':                              'float32',\n",
    "        'Census_ChassisTypeName':                               'category',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',\n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',\n",
    "        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',\n",
    "        'Census_PowerPlatformRoleName':                         'category',\n",
    "        'Census_InternalBatteryType':                           'category',\n",
    "        'Census_InternalBatteryNumberOfCharges':                'float32',\n",
    "        'Census_OSVersion':                                     'category',\n",
    "        'Census_OSArchitecture':                                'category',\n",
    "        'Census_OSBranch':                                      'category',\n",
    "        'Census_OSBuildNumber':                                 'int16',\n",
    "        'Census_OSBuildRevision':                               'int32',\n",
    "        'Census_OSEdition':                                     'category',\n",
    "        'Census_OSSkuName':                                     'category',\n",
    "        'Census_OSInstallTypeName':                             'category',\n",
    "        'Census_OSInstallLanguageIdentifier':                   'float16',\n",
    "        'Census_OSUILocaleIdentifier':                          'int16',\n",
    "        'Census_OSWUAutoUpdateOptionsName':                     'category',\n",
    "        'Census_IsPortableOperatingSystem':                     'int8',\n",
    "        'Census_GenuineStateName':                              'category',\n",
    "        'Census_ActivationChannel':                             'category',\n",
    "        'Census_IsFlightingInternal':                           'float16',\n",
    "        'Census_IsFlightsDisabled':                             'float16',\n",
    "        'Census_FlightRing':                                    'category',\n",
    "        'Census_ThresholdOptIn':                                'float16',\n",
    "        'Census_FirmwareManufacturerIdentifier':                'float16',\n",
    "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
    "        'Census_IsSecureBootEnabled':                           'int8',\n",
    "        'Census_IsWIMBootEnabled':                              'float16',\n",
    "        'Census_IsVirtualDevice':                               'float16',\n",
    "        'Census_IsTouchEnabled':                                'int8',\n",
    "        'Census_IsPenCapable':                                  'int8',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n",
    "        'Wdft_IsGamer':                                         'float16',\n",
    "        'Wdft_RegionIdentifier':                                'float16',\n",
    "        'HasDetections':                                        'int8'\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download Train and Test Data.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#读取训练集和测试集文档\n",
    "#将训练集和测试集中的第0列特征'MachineIdentifier'转为'uint32'类型。  就理解为机器ID,很好！\n",
    "print('Download Train and Test Data.\\n')\n",
    "path=\"D:\\\\360安全浏览器下载\\\\Microsoft_Malware_Prediction\\\\microsoft-malware-prediction\"\n",
    "train = pd.read_csv(open((path+'\\\\train.csv'),encoding='utf-8'), dtype=dtypes, low_memory=True)\n",
    "train['MachineIdentifier'] = train.index.astype('uint32')\n",
    "test  = pd.read_csv(open((path+'\\\\test.csv'),encoding='utf-8'),  dtype=dtypes, low_memory=True)\n",
    "test['MachineIdentifier']  = test.index.astype('uint32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201376"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#垃圾回收\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform all features to category.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Transform all features to category.\\n')\n",
    "#将所有特征转化为类类型。\n",
    "#一个一个慢慢来。\n",
    "for usecol in train.columns.tolist()[1:-1]:   #此句易让人误解成只对训练集操作，其实不然，它只是想抽出一个特征向量名字的列表。\n",
    "    \n",
    "\n",
    "    #先把训练集以及测试集中的此特征string化。\n",
    "    train[usecol] = train[usecol].astype('str')\n",
    "    test[usecol] = test[usecol].astype('str')\n",
    "    \n",
    "    #Fit LabelEncoder\n",
    "    #标签编码器，对此某特征，将训练集中的独特值和测试集中的独特值放在一起，再unique()化，然后将LabelEncoder跟这个序列匹配。\n",
    "    le = LabelEncoder().fit(\n",
    "            np.unique(train[usecol].unique().tolist()+\n",
    "                      test[usecol].unique().tolist()))\n",
    "\n",
    "    #At the end 0 will be used for dropped values\n",
    "    #这里transform后还加1自然有它的道理，因为后面会给丢弃值或缺失值赋为0.\n",
    "    train[usecol] = le.transform(train[usecol])+1\n",
    "    test[usecol]  = le.transform(test[usecol])+1\n",
    "\n",
    "    #count统计的是分组中非NA值的数量。这个函数统计相当于统计该特征每个unique()值及其对应的数量，得到的是一个Series.然后把列名从ID分别改为\n",
    "    # Train,Test.\n",
    "    agg_tr = (train\n",
    "              .groupby([usecol])\n",
    "              .aggregate({'MachineIdentifier':'count'})\n",
    "              .reset_index()\n",
    "              .rename({'MachineIdentifier':'Train'}, axis=1))\n",
    "    agg_te = (test\n",
    "              .groupby([usecol])\n",
    "              .aggregate({'MachineIdentifier':'count'})\n",
    "              .reset_index()\n",
    "              .rename({'MachineIdentifier':'Test'}, axis=1))\n",
    "    \n",
    "    #把以上两个Series合并到一起成一个DataFrame，名为agg链接键为该特征向量，并将合并后的agg中的NAN值赋为0.\n",
    "    agg = pd.merge(agg_tr, agg_te, on=usecol, how='outer').replace(np.nan, 0)\n",
    "    #Select values with more than 1000 observations\n",
    "    \n",
    "    #agg只取'Train'值大于1000的部分，重新排列索引，这个(drop=True)一定要写，意为返回一个DataFrame或者Series.\n",
    "    agg = agg[(agg['Train'] > 1000)].reset_index(drop=True)\n",
    "    \n",
    "    #agg新增一列‘Total’，为agg['Train'] + agg['Test'].\n",
    "    agg['Total'] = agg['Train'] + agg['Test']\n",
    "    #Drop unbalanced values\n",
    "    #只取Train占比在0.2到0.8之间的部分。\n",
    "    agg = agg[(agg['Train'] / agg['Total'] > 0.2) & (agg['Train'] / agg['Total'] < 0.8)]\n",
    "    #得到该df的一个复制版本的df.\n",
    "    agg[usecol+'Copy'] = agg[usecol]\n",
    "    \n",
    "    #最终目的展露：将训练集中的该列与agg[[usecol, usecol+'Copy']]合并，取合并结果中的usecol+'Copy',赋给训练集中的该列。并将其先转为\n",
    "    #int类型，再转为category类型。\n",
    "    train[usecol] = (pd.merge(train[[usecol]], \n",
    "                              agg[[usecol, usecol+'Copy']], \n",
    "                              on=usecol, how='left')[usecol+'Copy']\n",
    "                     .replace(np.nan, 0).astype('int').astype('category'))\n",
    "\n",
    "    #同上。\n",
    "    test[usecol]  = (pd.merge(test[[usecol]], \n",
    "                              agg[[usecol, usecol+'Copy']], \n",
    "                              on=usecol, how='left')[usecol+'Copy']\n",
    "                     .replace(np.nan, 0).astype('int').astype('category'))\n",
    "    \n",
    "#这mission completed,些中间变量留着也没神马用了，就给删了，再来个垃圾回收。\n",
    "    del le, agg_tr, agg_te, agg, usecol\n",
    "    gc.collect()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train['HasDetections'])\n",
    "train_ids = train.index\n",
    "test_ids  = test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=8921483, step=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=7853253, step=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将训练集中的'HasDetections'列，训练集及测试集中的ID列删除\n",
    "#垃圾回收\n",
    "del train['HasDetections'], train['MachineIdentifier'], test['MachineIdentifier']\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you don't want use Sparse Matrix choose Kernel Version 2 to get simple solution.\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------\n",
      "Transform Data to Sparse Matrix.\n",
      "Sparse Matrix can be used to fit a lot of models, eg. XGBoost, LightGBM, Random Forest, K-Means and etc.\n",
      "To concatenate Sparse Matrices by column use hstack()\n",
      "Read more about Sparse Matrix https://docs.scipy.org/doc/scipy/reference/sparse.html\n",
      "Good Luck!\n",
      "--------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#一堆废话，提示语句\n",
    "print(\"If you don't want use Sparse Matrix choose Kernel Version 2 to get simple solution.\\n\")\n",
    "\n",
    "print('--------------------------------------------------------------------------------------------------------')\n",
    "print('Transform Data to Sparse Matrix.')\n",
    "print('Sparse Matrix can be used to fit a lot of models, eg. XGBoost, LightGBM, Random Forest, K-Means and etc.')\n",
    "print('To concatenate Sparse Matrices by column use hstack()')\n",
    "print('Read more about Sparse Matrix https://docs.scipy.org/doc/scipy/reference/sparse.html')\n",
    "print('Good Luck!')\n",
    "print('--------------------------------------------------------------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#独热编码器，与训练集匹配一下。\n",
    "ohe = OneHotEncoder(categories='auto', sparse=True, dtype='uint8').fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1141"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#先把训练集，测试集中的每一行进行独热编码。\n",
    "#得到稀疏矩阵文件\n",
    "m = 100000\n",
    "train = vstack([ohe.transform(train[i*m:(i+1)*m]) for i in range(train.shape[0] // m + 1)])\n",
    "test  = vstack([ohe.transform(test[i*m:(i+1)*m])  for i in range(test.shape[0] // m +  1)])\n",
    "save_npz('train.npz', train, compressed=True)\n",
    "save_npz('test.npz',  test,  compressed=True)\n",
    "\n",
    "#删除无用变量并进行垃圾回收\n",
    "del ohe, train, test\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "skf.get_n_splits(train_ids, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#测试集结果，赋初始值为0.\n",
    "lgb_test_result  = np.zeros(test_ids.shape[0])\n",
    "#lgb_train_result = np.zeros(train_ids.shape[0])\n",
    "#xgb_test_result  = np.zeros(test_ids.shape[0])\n",
    "#xgb_train_result = np.zeros(train_ids.shape[0])\n",
    "\n",
    "#全局计数变量counter,赋初始值为0.\n",
    "counter = 0\n",
    "\n",
    "print('\\nLightGBM\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\tvalid_0's binary_logloss: 0.604756\tvalid_0's auc: 0.731814\n",
      "[200]\tvalid_0's binary_logloss: 0.598171\tvalid_0's auc: 0.737255\n",
      "[300]\tvalid_0's binary_logloss: 0.596577\tvalid_0's auc: 0.738762\n",
      "[400]\tvalid_0's binary_logloss: 0.596246\tvalid_0's auc: 0.73902\n",
      "[500]\tvalid_0's binary_logloss: 0.596295\tvalid_0's auc: 0.738941\n",
      "Early stopping, best iteration is:\n",
      "[413]\tvalid_0's binary_logloss: 0.596234\tvalid_0's auc: 0.739032\n"
     ]
    }
   ],
   "source": [
    "#四一分，得到训练集和验证集。\n",
    "for train_index, test_index in skf.split(train_ids, y_train):\n",
    "    \n",
    "    #意为第1折，2折，3折，4折，5折的结果\n",
    "    print('Fold {}\\n'.format(counter + 1))\n",
    "    \n",
    "    #读取训练集的稀疏矩阵文件\n",
    "    train = load_npz('train.npz')\n",
    "    #我感觉这么做的目的是慢慢来，以防卡死。\n",
    "    X_fit = vstack([train[train_index[i*m:(i+1)*m]] for i in range(train_index.shape[0] // m + 1)])\n",
    "    X_val = vstack([train[test_index[i*m:(i+1)*m]]  for i in range(test_index.shape[0] //  m + 1)])\n",
    "   \n",
    "    #将训练集的两部分（“训练集” X_fit和验证集X_val）X稀疏矩阵化，再对y_fit, y_val进行赋值。\n",
    "    X_fit, X_val = csr_matrix(X_fit, dtype='float32'), csr_matrix(X_val, dtype='float32')\n",
    "    y_fit, y_val = y_train[train_index], y_train[test_index]\n",
    "    \n",
    "    #删掉训练集并垃圾回收，这一步讲真不是很理解。\n",
    "    del train\n",
    "    gc.collect()\n",
    "\n",
    "    #建立lgb模型。\n",
    "    lgb_model = lgb.LGBMClassifier(max_depth=-1,\n",
    "                                   n_estimators=30000,\n",
    "                                   learning_rate=0.05,\n",
    "                                   num_leaves=2**12-1,\n",
    "                                   colsample_bytree=0.28,\n",
    "                                   objective='binary', \n",
    "                                   n_jobs=-1)\n",
    "                                   \n",
    "    \n",
    "                               \n",
    "    #让lgb模型与该“训练集”X_fit，y_fit适配一下。\n",
    "    #评估机制是ROC曲线以下的区域面积。评估集是X_val, y_val。\n",
    "    lgb_model.fit(X_fit, y_fit, eval_metric='auc', \n",
    "                  eval_set=[(X_val, y_val)], \n",
    "                  verbose=100, early_stopping_rounds=100)\n",
    "                  \n",
    "   \n",
    "    #X_fit, X_val, y_fit, y_val, train_index, test_index全部用不着了，全部删除并进行垃圾回收。\n",
    "    del X_fit, X_val, y_fit, y_val, train_index, test_index\n",
    "    gc.collect()\n",
    "   \n",
    "    #测试集\n",
    "    #加载出测试集的稀疏矩阵文件。\n",
    "    #该折的预测结果叠加到lgb_test_result 上。\n",
    "    test = load_npz('test.npz')\n",
    "    test = csr_matrix(test, dtype='float32')\n",
    "    lgb_test_result += lgb_model.predict_proba(test)[:,1]\n",
    "   \n",
    "    #计数器counter的值加一。\n",
    "    counter += 1\n",
    "   \n",
    "    #把测试集test扔掉。\n",
    "    del test\n",
    "    gc.collect()\n",
    "    \n",
    "    #Stop fitting to prevent time limit error\n",
    "    #if counter == 3 : break\n",
    "\n",
    "#print('\\nLigthGBM VAL AUC Score: {}'.format(roc_auc_score(y_train, lgb_train_result)))\n",
    "#print('\\nXGBoost VAL AUC Score: {}'.format(roc_auc_score(y_train, xgb_train_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这样倒是非常省事，直接在题目给的submission上改动。\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['HasDetections'] = lgb_test_result / counter\n",
    "submission.to_csv('lgb_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
